{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f29d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "from utils.segmentation import yolo_to_tf_centered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b839fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# CONFIG\n",
    "# ======================\n",
    "\n",
    "LABEL_DIR = \"path/to/labels/directory/\"  # dossier YOLO prédictions\n",
    "CSV_PATH = \"path/to/annotations/\"\n",
    "CSV_INPUT = \"annotations_trills.csv\"\n",
    "CSV_PATH = Path(CSV_PATH) / CSV_INPUT\n",
    "OUT_CSV = \"annotations_trills_with_pred.csv\"\n",
    "OUT_CSV = Path(CSV_PATH).parent / OUT_CSV\n",
    "\n",
    "sr = 44100\n",
    "win_len = 2.0\n",
    "f_max_global = sr / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf3291",
   "metadata": {},
   "source": [
    "### Add predictions of YOLO model to Annotated CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a388c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# MAIN\n",
    "# ======================\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df[\"trill_t_start_pred\"] = np.nan\n",
    "df[\"trill_t_end_pred\"] = np.nan\n",
    "df[\"trill_f_min_pred\"] = np.nan\n",
    "df[\"trill_f_max_pred\"] = np.nan\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "\n",
    "    stem = Path(row[\"file_name_radical\"]).stem\n",
    "    seg_id = row[\"segment_id\"]\n",
    "\n",
    "    txt_path = Path(LABEL_DIR) / f\"{stem}_seg{seg_id}.txt\"\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Processing {txt_path} \")\n",
    "\n",
    "    if not txt_path.exists() or txt_path.stat().st_size == 0:\n",
    "        continue\n",
    "\n",
    "    with open(txt_path) as f:\n",
    "        line = f.readline().strip()\n",
    "\n",
    "    parts = line.split()\n",
    "\n",
    "    if len(parts) < 5:\n",
    "        continue\n",
    "\n",
    "    _, xc, yc, w, h = map(float, parts[:5])\n",
    "\n",
    "    # YOLO → relatif segment\n",
    "    t0_rel, t1_rel, f0, f1 = yolo_to_tf_centered(xc, yc, w, h, win_len, f_max_global)\n",
    "\n",
    "    # relatif → absolu audio\n",
    "    seg_start = row[\"time_start\"]\n",
    "\n",
    "    df.loc[idx, \"trill_t_start_pred\"] = t0_rel + seg_start\n",
    "    df.loc[idx, \"trill_t_end_pred\"] = t1_rel + seg_start\n",
    "    df.loc[idx, \"trill_f_min_pred\"] = f0\n",
    "    df.loc[idx, \"trill_f_max_pred\"] = f1\n",
    "\n",
    "# ======================\n",
    "# SAVE\n",
    "# ======================\n",
    "\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"✅ CSV enrichi sauvegardé\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f113adea",
   "metadata": {},
   "source": [
    "### Export WAV files from the detected segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b79de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_trill_audio_segments(\n",
    "    df,\n",
    "    audio_dir,\n",
    "    output_dir,\n",
    "    sample_rate=None,\n",
    "    padding_ratio=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Export trill audio segments with temporal padding.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns:\n",
    "        ['file_name', 'file_name_radical', 'time_start',\n",
    "         'trill_t_start', 'trill_t_end']\n",
    "    audio_dir : str\n",
    "        Directory containing the original audio files\n",
    "    output_dir : str\n",
    "        Directory where cropped files will be written\n",
    "    sample_rate : int or None\n",
    "        If None, keep native sampling rate\n",
    "    padding_ratio : float\n",
    "        Fraction of trill duration added on each side\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    empty_files = []\n",
    "    for _, row in df.iterrows():\n",
    "        audio_path = os.path.join(audio_dir, row[\"file_name_radical\"])\n",
    "\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"Missing file: {audio_path}\")\n",
    "            continue\n",
    "\n",
    "        t_start = row[\"trill_t_start_pred\"]\n",
    "        t_end = row[\"trill_t_end_pred\"]\n",
    "\n",
    "        if np.isnan(t_start) or np.isnan(t_end) or t_start >= t_end:\n",
    "            print(f\"Invalid times for {audio_path}: start={t_start}, end={t_end}\")\n",
    "            empty_files.append(audio_path)\n",
    "            continue\n",
    "\n",
    "        if row[\"file_name_radical\"] in [\"Luscinia_svecica_654083.wav\"]:\n",
    "            print(f\"Skipping file with known issues: {audio_path}\")\n",
    "            print(f\"Times: start={t_start}, end={t_end}\")\n",
    "            continue\n",
    "\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(audio_path, sr=sample_rate, mono=True)\n",
    "\n",
    "        # Padding\n",
    "        duration = t_end - t_start\n",
    "        pad = padding_ratio * duration\n",
    "\n",
    "        t_start_pad = max(0, t_start - pad)\n",
    "        t_end_pad = min(len(y) / sr, t_end + pad)\n",
    "\n",
    "        # Convert to samples\n",
    "        s_start = int(t_start_pad * sr)\n",
    "        s_end = int(t_end_pad * sr)\n",
    "\n",
    "        y_crop = y[s_start:s_end]\n",
    "\n",
    "        output_file_name = f\"{row['file_name_radical'].split('.')[0]}_seg{row['segment_id']}.wav\"\n",
    "        # Output path\n",
    "        out_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "        # Write audio\n",
    "        sf.write(out_path, y_crop, sr)\n",
    "\n",
    "    if empty_files:\n",
    "        print(f\"Number of files with invalid times: {len(empty_files)}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"path/to/trill_segments_detected/\"\n",
    "AUDIO_DIR = \"path/to/audio/files/\"\n",
    "DATA_DIR = \"path/to/annotation/file/\"\n",
    "\n",
    "trill_rate_annotation_file = \"annotations_trills_with_pred.csv\"\n",
    "df_annotation_rhythm = pd.read_csv(os.path.join(DATA_DIR, trill_rate_annotation_file))\n",
    "\n",
    "export_trill_audio_segments(\n",
    "    df=df_annotation_rhythm,\n",
    "    audio_dir=AUDIO_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    sample_rate=None,     # conserve le SR natif\n",
    "    padding_ratio=0.05\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
